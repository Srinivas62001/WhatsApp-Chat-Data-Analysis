{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "5rfq41GzHG3F"
   },
   "source": [
    "# WhatsApp Chat Data Analysis"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "EUano4akPP24"
   },
   "source": [
    "I have planned to do a brief data analysis on the WhatsApp Chat to get a better understanding of the type of messages, timeline of the messages and to obtain a brief statistics of the messages I receive over whatsapp. I have extracted the chat from one of my college whatsapp group and have exported here to analyze it. Here, I would be using various python libraries like numpy, pandas, regex, nltk, matplotlib, seaborn etc to get a clear visualization of the data."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "9lVYr2pwQa-Z"
   },
   "source": [
    "### Installing the required modules"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "Y7qiCnz-yzxy",
    "outputId": "c9075479-df07-49ab-be5d-92fb4f2153bb"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting urlextract\n",
      "  Downloading urlextract-1.6.0-py3-none-any.whl (20 kB)\n",
      "Requirement already satisfied: idna in c:\\programdata\\anaconda3\\lib\\site-packages (from urlextract) (2.10)\n",
      "Collecting platformdirs\n",
      "  Downloading platformdirs-2.5.2-py3-none-any.whl (14 kB)\n",
      "Collecting uritools\n",
      "  Downloading uritools-4.0.0-py3-none-any.whl (10 kB)\n",
      "Requirement already satisfied: filelock in c:\\programdata\\anaconda3\\lib\\site-packages (from urlextract) (3.0.12)\n",
      "Installing collected packages: uritools, platformdirs, urlextract\n",
      "Successfully installed platformdirs-2.5.2 uritools-4.0.0 urlextract-1.6.0\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip install urlextract"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "lPmbM2TZ3sdz",
    "outputId": "22b91c6f-d545-4a1f-cf70-76087f8eda94"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting emoji\n",
      "  Downloading emoji-2.0.0.tar.gz (197 kB)\n",
      "Building wheels for collected packages: emoji\n",
      "  Building wheel for emoji (setup.py): started\n",
      "  Building wheel for emoji (setup.py): finished with status 'done'\n",
      "  Created wheel for emoji: filename=emoji-2.0.0-py3-none-any.whl size=193004 sha256=9519b9c494157a5baccbef07e465048746100d95097c3086e199569340b97ab3\n",
      "  Stored in directory: c:\\users\\srinivas n\\appdata\\local\\pip\\cache\\wheels\\23\\a5\\a8\\e74bad1ceced228b6ae94dcbacc5c67df6486fd1620714e7d1\n",
      "Successfully built emoji\n",
      "Installing collected packages: emoji\n",
      "Successfully installed emoji-2.0.0\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip install emoji"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "MkYDPYvQQcid"
   },
   "source": [
    "### Importing Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "id": "n-a-Y55o8-6h"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\scipy\\__init__.py:138: UserWarning: A NumPy version >=1.16.5 and <1.23.0 is required for this version of SciPy (detected version 1.23.1)\n",
      "  warnings.warn(f\"A NumPy version >={np_minversion} and <{np_maxversion} is required for this version of \"\n"
     ]
    },
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'wordcloud'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-3-17a7141a4384>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      4\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mseaborn\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0msns\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      5\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[0murlextract\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mURLExtract\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 6\u001b[1;33m \u001b[1;32mfrom\u001b[0m \u001b[0mwordcloud\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mWordCloud\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      7\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[0mcollections\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mCounter\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      8\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0memoji\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mModuleNotFoundError\u001b[0m: No module named 'wordcloud'"
     ]
    }
   ],
   "source": [
    "import re\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from urlextract import URLExtract\n",
    "from wordcloud import WordCloud\n",
    "from collections import Counter\n",
    "import emoji"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "CsW8ibIORXwp"
   },
   "source": [
    "### Importing the Whatsapp Chat text file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "HE4-GfdLHF4U"
   },
   "outputs": [],
   "source": [
    "f = open('WhatsApp Chat with Aero19.txt', 'r', encoding = 'utf-8')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "QV6XsoohHpsL"
   },
   "outputs": [],
   "source": [
    "data = f.read()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "aGYvGzcGHtqm",
    "outputId": "dc1b8063-62a1-4d21-95b7-b60f3888799e"
   },
   "outputs": [],
   "source": [
    "print(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "kMQRz5KKHuOa",
    "outputId": "ac8b5207-98b6-4d65-ae83-deee8aa4cbd3"
   },
   "outputs": [],
   "source": [
    "type(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "Iut2B-mHH5lY"
   },
   "outputs": [],
   "source": [
    "pattern = '\\d{1,2}[\\/]\\d{1,2}[\\/]\\d{2,4}, \\d{1,2}:\\d{1,2} [a|p]m - '"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "60yi4zubKT5a",
    "outputId": "37dbd80b-50c2-456b-c0d8-ebeb293e022b"
   },
   "outputs": [],
   "source": [
    "messages = re.split(pattern, data)[1:]\n",
    "messages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "PbbRx9lOKfUE",
    "outputId": "6d0a992f-b969-4ced-d25d-4ef4f5accc7a"
   },
   "outputs": [],
   "source": [
    "dates = re.findall(pattern, data)\n",
    "dates"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "PperO7ZDSivx"
   },
   "source": [
    "A dataframe is formed with user_message and date as columns obtained using regex through split function with respect to the pattern mentioned."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 206
    },
    "id": "zJzrgwAnKvZc",
    "outputId": "78099d2b-fccc-4eeb-e114-4385ef12f610"
   },
   "outputs": [],
   "source": [
    "df = pd.DataFrame({'user_message': messages, 'message_date': dates})\n",
    "\n",
    "df['message_date'] = pd.to_datetime(df['message_date'], format='%d/%m/%Y, %I:%M %p - ')\n",
    "\n",
    "df.rename(columns={'message_date': 'date'}, inplace=True)\n",
    "\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "IoLKTw_2LkTE",
    "outputId": "473f2cb0-0b36-4f50-ef5b-5eae761ea699"
   },
   "outputs": [],
   "source": [
    "df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "E8Im3d1jQHW_"
   },
   "outputs": [],
   "source": [
    "users = []\n",
    "messages = []\n",
    "for message in df['user_message']:\n",
    "    entry = re.split('([\\w\\W]+?): ', message)\n",
    "    if entry[1:]:  # user name\n",
    "        users.append(entry[1])\n",
    "        messages.append(\" \".join(entry[2:]))\n",
    "    else:\n",
    "        users.append('group_notification')\n",
    "        messages.append(entry[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "4IkQ-hKhRjAk"
   },
   "outputs": [],
   "source": [
    "df['user'] = users\n",
    "df['message'] = messages"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "nbVnftu6TNTC"
   },
   "source": [
    "Once again using regex split function, the dataset is further being splitted dividing the user_messages into usernames and the specific messages. All the group notification messages are being assigned to a user named as group_notification to avoid confusion."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 424
    },
    "id": "wUeKS3WoSrC1",
    "outputId": "6cc3132e-770f-472c-fa8e-2f3652130976"
   },
   "outputs": [],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "xLWbpeGeVWX_"
   },
   "source": [
    "The date column is also split into various sub branches like year, month, day, hour, minute and many more using the dt attribute of datetime in pandas and have been added into the dataset using separate columns."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 337
    },
    "id": "sVRpmi0hUrt4",
    "outputId": "03de372c-afc7-4e98-82a3-9629afb0460e"
   },
   "outputs": [],
   "source": [
    "df['year'] = df['date'].dt.year\n",
    "df['month'] = df['date'].dt.month_name()\n",
    "df['month_num'] = df['date'].dt.month\n",
    "df['day'] = df['date'].dt.day\n",
    "df['only_date'] = df['date'].dt.date\n",
    "df['day_name'] = df['date'].dt.day_name()\n",
    "df['hour'] = df['date'].dt.hour\n",
    "df['minute'] = df['date'].dt.minute\n",
    "\n",
    "\n",
    "\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "_RwrPwq0ZiH1"
   },
   "outputs": [],
   "source": [
    "df.drop(columns = ['user_message'], inplace = True, axis = 1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Ibg_9u6UWDU8"
   },
   "source": [
    "This would be the final dataset, df which we would be using to analyze the chat data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 424
    },
    "id": "P8NFElqJnAVe",
    "outputId": "505bf700-a3a2-4569-c4a7-fdacb907ad13"
   },
   "outputs": [],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "frVe3eArfoHz"
   },
   "source": [
    "## Statistical Data Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "vCG89pDhnLjO",
    "outputId": "55905767-9b06-43ca-85f2-e7221b20d6ac"
   },
   "outputs": [],
   "source": [
    "user_list = df['user'].unique().tolist()\n",
    "user_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "AY-w8LzcncZD",
    "outputId": "b18697a5-58d4-4c39-f341-36da1d537ec5"
   },
   "outputs": [],
   "source": [
    "user_list.remove('group_notification')\n",
    "user_list.sort()\n",
    "user_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "SPdJzhDknnPi",
    "outputId": "b06109ab-45a9-481f-f030-638cae66b021"
   },
   "outputs": [],
   "source": [
    "len(user_list)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "-pTSURZEWfwf"
   },
   "source": [
    "This shows that, from the day it is created there are 83 users involved in this whatsapp group."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "jkwMCJN3riXm"
   },
   "outputs": [],
   "source": [
    "def fetch_stats(selected_user, df):\n",
    "  if selected_user != 'Overall':\n",
    "    df = df[df['user'] == selected_user]\n",
    "\n",
    "  # Number of messages and total number of words\n",
    "  num_messages = df.shape[0]\n",
    "  words = []\n",
    "  for message in df['message']:\n",
    "    words.extend(message.split())\n",
    "\n",
    "  # Number of media messages\n",
    "  num_media_messages = df[df['message'] == '<Media omitted>\\n'].shape[0]\n",
    "\n",
    "  # Number of links shared\n",
    "  extract = URLExtract()\n",
    "  links = []\n",
    "  for message in df['message']:\n",
    "    links.extend(extract.find_urls(message))\n",
    "\n",
    "\n",
    "  print(\"Total Number of Messages - {}, Total Number of Words - {}, Number of Media shared - {}, Number of links shared - {}\".format(num_messages, len(words), num_media_messages, len(links)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "_tDsgbBNXKdn"
   },
   "source": [
    "The fetch_stats(selected_user, df) function returns some of the Statistical analysis of the chats of the group, both overall as a group and of a selected user of the group. It returns total number of messages and words involved in the chat and also we would get to know how many media and links are being shared over the group both overall and by an user shared to the group."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "budK5WpDt3qW",
    "outputId": "32274c8c-d5d4-4e7c-e899-f34d0fe99f7b"
   },
   "outputs": [],
   "source": [
    "fetch_stats('Overall', df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "m44RlmZjt-BQ",
    "outputId": "6eb74de6-6638-4335-a3cf-d85e2b98df1b"
   },
   "outputs": [],
   "source": [
    "fetch_stats('Srinivas N', df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "tGwxMrLgYXdY"
   },
   "source": [
    "We could ge to know about the busiest persons of the group, who basically being active sends too many messages. most_busy_users(df) function returns top 5 busiest users of the group. A bar graph is plotted to obtain a better view of this stat."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 753
    },
    "id": "jgv1Ui3FvNpn",
    "outputId": "ef4f545e-2a07-4f19-9b87-78aa59ba3920"
   },
   "outputs": [],
   "source": [
    "# Busiest users in the group\n",
    "def most_busy_users(df):\n",
    "  x = df['user'].value_counts().head()\n",
    "  new_df = round((df['user'].value_counts() / df.shape[0]) * 100, 2).reset_index().rename(\n",
    "        columns={'index': 'name', 'user': 'percent'})\n",
    "  plt.bar(x.index, x.values, color = 'indigo')\n",
    "  plt.rcParams['figure.figsize'] = [15, 15]\n",
    "  plt.xticks(rotation = 'vertical')\n",
    "  plt.show()\n",
    "  return new_df\n",
    "\n",
    "most_busy_users(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "G2xL3pl2Ct5O"
   },
   "outputs": [],
   "source": [
    "# most common used words\n",
    "\n",
    "def most_common_words(selected_user, df):\n",
    "  f = open('stop_hinglish.txt', 'r')\n",
    "  stop_words = f.read()\n",
    "\n",
    "  if selected_user != 'Overall':\n",
    "    df = df[df['user'] == selected_user]\n",
    "\n",
    "  temp = df[df['user'] != 'group_notification']\n",
    "  temp = temp[temp['message'] != '<Media omitted>\\n']  \n",
    "\n",
    "  words = []\n",
    "  for message in temp['message']:\n",
    "    for word in message.lower().split():\n",
    "        if word not in stop_words:\n",
    "            words.append(word)\n",
    "\n",
    "  most_common_df = pd.DataFrame(Counter(words).most_common(20))\n",
    "  \n",
    "  plt.barh(most_common_df[0], most_common_df[1], color = 'green')\n",
    "  plt.xticks(rotation = 'vertical')\n",
    "  plt.title('Most Common Words', fontsize = 25)\n",
    "  plt.show()\n",
    "  return most_common_df\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "zwZQSqXigZoL"
   },
   "source": [
    "most_common_words(selected_user, df) function returns most common used words in the messages of both overall as a group and of a selected user of the group. Here, I have used a file named stop_hinglish.txt having some unwanted texts (the words like 'a', 'the', 'is' and many more Indianized chat words ) and this acts a stop words here and filters the words required in this analysis."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "id": "E4RTWZl7gRUN",
    "outputId": "f21f74c0-e419-4a7d-bef7-bcbea3a6100b"
   },
   "outputs": [],
   "source": [
    "most_common_words('Overall', df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "id": "aAOfSub3Gvlm",
    "outputId": "45627617-f167-4db6-bf26-e52f357aa8e2"
   },
   "outputs": [],
   "source": [
    "most_common_words('Srinivas N', df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "xtmreEMxf55g"
   },
   "source": [
    "### Most common words using NLP"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "JRAIVglnbX52"
   },
   "source": [
    "The libraries required for the Natural Language Processing are being downloaded here."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "2hBpV2Me5QNu",
    "outputId": "620e8f0d-5ee8-49c5-df0a-63c7d2c5cf74"
   },
   "outputs": [],
   "source": [
    "import nltk\n",
    "nltk.download('stopwords')\n",
    "nltk.download('punkt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "30dOoj7d5PZv"
   },
   "outputs": [],
   "source": [
    "from nltk.tokenize import word_tokenize\n",
    "from string import punctuation\n",
    "from nltk.corpus import stopwords\n",
    "from nltk import FreqDist"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "HASJ3mrzb1Z4"
   },
   "source": [
    "We can obtain most common used words in the messages using NLP as well and here we are doing it. Here we use word_tokenize() to split the text into tokens or words and the also the punctuation from string is used as one of the source for unwanted texts which filters the punctuations involved in the texts. Stopwords of nltk.corpus has stop words and we can get them by mentioning the language (here English) and it acts as stop words helping in filtering the words required for the analysis. Also, I have used stop_hinglish.txt as another source of stop words and used it here as well in filtering the words. Mainly here I have implemented regex which is compiled with pattern '[a-zA-Z]' which matches only with the alphabetic words (to be precise, words which starts with alphabetic words) where numbers and other extras like punctuations are not being involved. Strictly speaking it only analyses alphabetical words and returns the most common used alphabetical words."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "5tfUWMQ47u3N"
   },
   "outputs": [],
   "source": [
    "def most_common_words_nlp_with_regex(selected_user, df):\n",
    "  f = open('stop_hinglish.txt', 'r')\n",
    "  stop_words = f.read()\n",
    "\n",
    "  if selected_user != 'Overall':\n",
    "    df = df[df['user'] == selected_user]\n",
    "\n",
    "  temp = df[df['user'] != 'group_notification']\n",
    "  temp = temp[temp['message'] != '<Media omitted>\\n']\n",
    "\n",
    "  tempar = \"\"\n",
    "  for char in temp['message']:\n",
    "    if char not in punctuation:\n",
    "      tempar += char\n",
    "  words = word_tokenize(tempar)\n",
    "\n",
    "  sw = set(stopwords.words(\"english\"))\n",
    "  filterd_words = [w.lower() for w in words if w not in sw]\n",
    "\n",
    "\n",
    "  new_words = []\n",
    "  for wor in filterd_words:\n",
    "    if wor not in stop_words:\n",
    "      new_words.append(wor)\n",
    "\n",
    "  regex = re.compile('[a-zA-Z]')\n",
    "\n",
    "  filtered = [i for i in new_words if regex.match(i)]\n",
    "\n",
    "  filtered = FreqDist(filtered)\n",
    "  most_common_df_nlp = pd.DataFrame(filtered.most_common(20))\n",
    "  return most_common_df_nlp\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 676
    },
    "id": "4tabryAd-AcT",
    "outputId": "1f9e3ea3-d88b-4a16-89d5-cbc091da48c7"
   },
   "outputs": [],
   "source": [
    "most_common_words_nlp_with_regex('Overall', df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 676
    },
    "id": "g80n5ApN_mCp",
    "outputId": "73a629d8-d9cf-4549-e2df-c7278b73ca80"
   },
   "outputs": [],
   "source": [
    "most_common_words_nlp_with_regex('Srinivas N', df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "5GZI0CERns2-"
   },
   "source": [
    "## Word Cloud"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "pG0eI7f81K0t"
   },
   "outputs": [],
   "source": [
    "def create_wordcloud(selected_user, df):\n",
    "  f = open('stop_hinglish.txt', 'r')\n",
    "  stop_words = f.read()\n",
    "\n",
    "  if selected_user != 'Overall':\n",
    "    df = df[df['user'] == selected_user]\n",
    "\n",
    "  temp = df[df['user'] != 'group_notification']\n",
    "  temp = temp[temp['message'] != '<Media omitted>\\n']\n",
    "\n",
    "  def remove_stop_words(message):\n",
    "    y = []\n",
    "    for word in message.lower().split():\n",
    "        if word not in stop_words:\n",
    "            y.append(word)\n",
    "    return \" \".join(y)\n",
    "\n",
    "    \n",
    "\n",
    "  wc = WordCloud(width = 1000, height = 1000, min_font_size = 10, background_color = 'white')\n",
    "  temp['message'] = temp['message'].apply(remove_stop_words)\n",
    "  df_wc = wc.generate(temp['message'].str.cat(sep = \" \"))\n",
    "  plt.title(\"Word Cloud\", fontsize = 25)\n",
    "  plt.imshow(df_wc)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "mvKfjqWnZC4O"
   },
   "source": [
    "create_wordcloud(selected_user, df) generates a word cloud (here, the size of each word indicates its frequency or importance in the chat) of the messages of both overall as a group and of a selected user of the group and it is visualized with a plot."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 888
    },
    "id": "QAnbcdk-MVgg",
    "outputId": "ecb7f24e-483f-4b1f-d820-caaaef81c4c2"
   },
   "outputs": [],
   "source": [
    "create_wordcloud('Overall', df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 888
    },
    "id": "6oqk6yOoA8hB",
    "outputId": "62d585ae-28a1-434e-9eee-ebb871a454db"
   },
   "outputs": [],
   "source": [
    "create_wordcloud('Srinivas N', df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "Aq-oVwSsHZ4k"
   },
   "outputs": [],
   "source": [
    "def most_common_emoji(selected_user,df):\n",
    "  if selected_user != 'Overall':\n",
    "    df = df[df['user'] == selected_user]\n",
    "\n",
    "  emojis = []\n",
    "  for message in df['message']:\n",
    "    emojis.extend([c for c in message if c in emoji.UNICODE_EMOJI['en']])\n",
    "\n",
    "  emoji_df = pd.DataFrame(Counter(emojis).most_common(len(Counter(emojis))))\n",
    "  plt.pie(emoji_df[1].head(), labels = emoji_df[0].head())\n",
    "  plt.show()\n",
    "\n",
    "  return emoji_df.head(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "l5450XIngm5C"
   },
   "source": [
    "most_common_emoji(selected_user,df) returns the most common used emoji in the messages of both overall as a group and of a selected user of the group and it is being visualized with a bar graph."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 311
    },
    "id": "qxQ8WXV4Nowj",
    "outputId": "cef03106-4510-49df-de31-9d62b65d5af2"
   },
   "outputs": [],
   "source": [
    "most_common_emoji('Overall', df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "JM_8U-B0NvjK"
   },
   "outputs": [],
   "source": [
    "most_common_emoji('Srinivas N', df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "03MQ8Crrfhf_"
   },
   "source": [
    "## Timeline Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "ox3zDo3uN08J"
   },
   "outputs": [],
   "source": [
    "def monthly_timeline(selected_user,df):\n",
    "\n",
    "    if selected_user != 'Overall':\n",
    "        df = df[df['user'] == selected_user]\n",
    "\n",
    "    timeline = df.groupby(['year', 'month_num', 'month']).count()['message'].reset_index()\n",
    "\n",
    "    time = []\n",
    "    for i in range(timeline.shape[0]):\n",
    "        time.append(timeline['month'][i] + \"-\" + str(timeline['year'][i]))\n",
    "\n",
    "    timeline['time'] = time\n",
    "\n",
    "    plt.plot(timeline['time'], timeline['message'], color = 'black')\n",
    "    plt.xticks(rotation = 'vertical')\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "fJ-AdgyJSBpS"
   },
   "source": [
    "monthly_timeline(selected_user,df) returns a plot of monthly timeline of the messages which depicts how the number of messages varied on monthly basis of both overall as a group and of a selected user of the group."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "PW-DWkpLROJ2"
   },
   "outputs": [],
   "source": [
    "monthly_timeline('Overall',df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "IOc6xAyIRSuS"
   },
   "outputs": [],
   "source": [
    "monthly_timeline('Srinivas N',df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "0AJPkuy7Ulvm"
   },
   "outputs": [],
   "source": [
    "def daily_timeline(selected_user,df):\n",
    "  if selected_user != 'Overall':\n",
    "    df = df[df['user'] == selected_user]\n",
    "\n",
    "  daily_timeline = df.groupby('only_date').count()['message'].reset_index()\n",
    "  plt.plot(daily_timeline['only_date'], daily_timeline['message'], color = 'yellow')\n",
    "  plt.xticks(rotation = 'vertical')\n",
    "  plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "RR0vUtx7SIJ1"
   },
   "source": [
    "daily_timeline(selected_user,df) returns a plot of daily timeline of the messages which depicts how the number of messages varied on daily basis with dates of different months of both overall as a group and of a selected user of the group."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "q938sdaSVKiB"
   },
   "outputs": [],
   "source": [
    "daily_timeline('Overall',df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "KGaptoqJVTHs"
   },
   "outputs": [],
   "source": [
    "daily_timeline('Srinivas N',df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "CaYYcVO4XIFy"
   },
   "outputs": [],
   "source": [
    "def week_activity_map(selected_user,df):\n",
    "  if selected_user != 'Overall':\n",
    "    df = df[df['user'] == selected_user]\n",
    "\n",
    "  busyday = df['day_name'].value_counts()\n",
    "\n",
    "  plt.bar(busyday.index, busyday.values, color = 'brown')\n",
    "  plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "F2813qaYSjXi"
   },
   "source": [
    "week_activity_map(selected_user,df) returns a bar plot of activity of the users on weekly basis from Sunday to Monday and returns how the number of messages vary on each day of the week, of both overall as a group and of a selected user of the group."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "I8jS7o39Xj0y"
   },
   "outputs": [],
   "source": [
    "week_activity_map('Overall',df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "HSqOFlspXqyZ"
   },
   "outputs": [],
   "source": [
    "week_activity_map('Srinivas N',df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "GBK7aGLuXxNt"
   },
   "outputs": [],
   "source": [
    "def month_activity_map(selected_user,df):\n",
    "  if selected_user != 'Overall':\n",
    "    df = df[df['user'] == selected_user]\n",
    "\n",
    "  busymonth = df['month'].value_counts()\n",
    "  \n",
    "  plt.bar(busymonth.index, busymonth.values, color = 'red')\n",
    "  plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "GF0WM-pNTttG"
   },
   "source": [
    "month_activity_map(selected_user,df) returns a bar plot of activity of the users on monthly basis from January to December and returns how the number of messages vary on each month of the year, of both overall as a group and of a selected user of the group."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "C3urqJYeaVPa"
   },
   "outputs": [],
   "source": [
    "month_activity_map('Overall',df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "plNTFtsLaZuS"
   },
   "outputs": [],
   "source": [
    "month_activity_map('Srinivas N',df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "UHCLA7tKbPUd"
   },
   "outputs": [],
   "source": [
    "period = []\n",
    "for hour in df[['day_name', 'hour']]['hour']:\n",
    "  if hour == 23:\n",
    "    period.append(str(hour) + \"-\" + str('00'))\n",
    "  elif hour == 0:\n",
    "    period.append(str('00') + \"-\" + str(hour + 1))\n",
    "  else:\n",
    "    period.append(str(hour) + \"-\" + str(hour + 1))\n",
    "\n",
    "df['period'] = period\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "koiqIGcKafPX"
   },
   "outputs": [],
   "source": [
    "def activity_heatmap(selected_user,df):\n",
    "  if selected_user != 'Overall':\n",
    "    df = df[df['user'] == selected_user]\n",
    "\n",
    "  plt.figure()\n",
    "  user_heatmap = sns.heatmap(df.pivot_table(index='day_name', columns='period', values='message', aggfunc='count').fillna(0))\n",
    "  plt.yticks(rotation = 'horizontal')\n",
    "  plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "oYyHj3j2UBFZ"
   },
   "source": [
    "activity_heatmap(selected_user, df) returns a heatmap of user activity plotted, based on time period of a day (24 hours, from 00 to 23 o' clock) varying with the days of the week from Sunday to Monday and returns how the number of messages vary on each day of the week with the time period, of both overall as a group and of a selected user of the group."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "hasnjImeciCV"
   },
   "outputs": [],
   "source": [
    "activity_heatmap('Overall',df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "-KRoDROudn2O"
   },
   "outputs": [],
   "source": [
    "activity_heatmap('Srinivas N',df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "u5oaqwP-es_O"
   },
   "outputs": [],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "H52-J57Tk7ds"
   },
   "source": [
    "## Sentiment Analysis"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "9bRYCZvwlFCJ"
   },
   "source": [
    "Importing the SentimentIntensityAnalyzer function from nltk required for the sentiment analysis of the chat."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "JnJQecwzfTiC"
   },
   "outputs": [],
   "source": [
    "from nltk.sentiment.vader import SentimentIntensityAnalyzer\n",
    "nltk.download('vader_lexicon')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "Tv_0A6VXfs6Q"
   },
   "outputs": [],
   "source": [
    "sentiments = SentimentIntensityAnalyzer()\n",
    "\n",
    "df['Positive'] = [sentiments.polarity_scores(i)[\"pos\"] for i in df[\"message\"]]\n",
    "df[\"Negative\"]=[sentiments.polarity_scores(i)[\"neg\"] for i in df[\"message\"]]\n",
    "df[\"Neutral\"]=[sentiments.polarity_scores(i)[\"neu\"] for i in df[\"message\"]]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "a2dGSMlHlnpT"
   },
   "source": [
    "The sentiment of the messages in the chat is being analyzed using polarity scores of the SentimentIntensityAnalyzer libraray and the messages are being divided into Positive, Negative and Neutral from the obtained result and have been updated them as separate new columns in the dataset, df."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "vcosedf9gqXX"
   },
   "outputs": [],
   "source": [
    "df.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "iD5g9Otoh0GT"
   },
   "outputs": [],
   "source": [
    "def sentiment_analyzer(selected_user, df):\n",
    "  if selected_user != 'Overall':\n",
    "    df = df[df['user'] == selected_user]\n",
    "\n",
    "  x=sum(df[\"Positive\"])\n",
    "  y=sum(df[\"Negative\"])\n",
    "  z=sum(df[\"Neutral\"])\n",
    "\n",
    "  dat = [x, y, z]\n",
    "  label = ['Positive', 'Negative', 'Neutral']\n",
    "\n",
    "  plt.pie(dat, labels = label)\n",
    "  plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "_68ZZXVgiIfp"
   },
   "outputs": [],
   "source": [
    "sentiment_analyzer('Overall', df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "rJF-qUwPm1G4"
   },
   "outputs": [],
   "source": [
    "sentiment_analyzer('Srinivas N', df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "umQjnvqVprri"
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [],
   "name": "Srinivas_N_WhatsApp_Chat_Data_Analysis.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
